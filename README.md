# Public Perception of COVID-19 Pandemic on Twitter

Ever since the start of COVID-19 pandemic, the social media has been overwhelmed with the news, updates, public reactions related to the pandemic. Ease of access to social media these days, has led to an exponential growth in posts, messages, video clips relating to the pandemic. Due to a lot of information overload, the mass frenzy has been observed that is caused due to wrong information circulated on the social media platforms about COVID-19 pandemic. Therefore, the analysis of the information about the pandemic, especially in early stages, that is circulated on social media is of utmost importance and will present a good case-study that shows how public opinion about the pandemic changed over the  period of time. This type of analytical case study is also helpful for social media platforms to put together the certain set of rules or measures to restrict the spread of misinformation on social media. This project only focuses on the Twitter platform, where lots of tweets had been generated since the start of pandemic in early 2020. This project will present the analysis of how public opinion changed, based on analysis of these tweets, over the period of time since beginning of 2020 and during various phases of pandemic such as lockdown phase, reopening phase, after the declaration of vaccine’s successful trial and the deployment of vaccine phase.  

# Sentiment Analysis
Sentiment Analysis is a Natural Language Processing technique, that deals with analysis of data for identifying the patterns and deducing the emotion behind that data. SentimentAnalysis is capable of classifying a piece of text/information into three broad categories based on underlying emotion. These three categories are Positive, Neutral and Negative. Broadly classifying, the algorithms used for sentiment analysis fall in one of the following three categories:  
1. **Rule-Based algorithms**: Rule-Based algorithms are the ones that work with previously decided sets of rules that helps in identifying the polarity or emotion of text. These types of algorithms use various Natural Language Processing techniques such as POS tagging, stemming, tokenization etc. Additionally, these algorithms also rely on emotion lexicons, which are essentially the lists of words and their corresponding association with a particular type of emotion or sentiment.    
2. **Automatic algorithms**: Automatic algorithms, as opposed to the Rule-Based algorithms, don't rely on any previously decided set of rules for sentiment classification. These algorithms use machine-learning models such as Naïve Bayes, Linear Regression, Support Vector Machine etc. for classification of the text in a particular category of emotion.  
3. **Hybrid algorithms**: Hybrid algorithms are the one that leverages the benefits of both Rule-Based and Automatic algorithms. These types of hybrid models tend to be very complex in nature and are computationally expensive, but achieve high accuracy in terms of classification of text into a certain sentiment/emotion category.  
  
*In this project, only Rule-Based and Automatic Sentiment Analysis methods are analyzed.*

# Data Description
For this project, two datasets are used. First dataset contains the tweets from various states in United States of America, around the timeline when two major phases of COVID-19 pandemic took place. These major phases are shut down and reopening phases. We used this data to understand and visualize the public sentiments about these two major decisions in a pandemic situation. This dataset contains 465,281 unique tweets, out of which 248,021 tweets are for shutdown phase and 217,260 tweets are for the reopening phase. In this project, we have used this data to perform exploratory analysis of the public sentiments/opinions about the shutdown and reopening decisions taken by government
officials in United States of America.  
Second dataset conations tweets related to COVID-19 vaccine announcements. This dataset consists of 826,379 unique tweets about the COVID vaccine. This dataset is used to train the machine/deep learning models for sentiment classification of tweets. So, this purpose we have split the whole dataset into train set, test set and validation set, each of which contains 661104, 165275 and 132220 tweets. As this dataset doesn’t contains the sentiment labels for each tweet, so we used a rulebased sentiment analysis model to assign a sentiment label to each tweet. After generating the labels with VADER, sentiment distribution of the data can be observed in Figure 1. We can see that the number of tweets that have negative sentiments and neutral sentiments are almost equal. However, total number of tweets with positive
sentiments are high compared to other two categories. So, in order to remove this imbalance from the dataset, we have randomly removed some of positive tweets in order to the match their numbers with the tweets in other sentiment classes.

# Rule Based Sentiment Analysis
In this project, we analyzed a very popular valance-based model, known as VADER [1] that stands for Valence Aware Dictionary and Sentiment Reasoner. VADER belongs to a type of sentiment analysis that is based on lexicons of sentimentrelated words. In this approach, each of the words in the lexicon is rated as to whether it is positive or negative or neutral. VADER is considered as valence-based, where the intensity of the sentiment is taken into account. VADER is specifically optimized for the social media platforms as it can conveniently identify emojis, word capitalizations etc. and is capable of taking them into account to compute sentiment score.While doing the literature review, we have come across various research materials that lauds the VADER lexicon for being very sensitive towards the text extracted from social media platforms. This has been mainly attributed to the fact that VADER, apart from following gold-standard lexicon rules also follows the grammatical and syntactical conventions. This helps VADER to understand the extra features inside the texts such as word capitalizations and emojis, and how they effect the overall tone and sentiment of the text. So, to understand and verify this fact, an experiment cn be crafted where a positive text is chosen, and its various similar forms are generated either by adding a new word, new punctuation marks, new emojis or by changing the letters of an important word from lowercase to uppercase. However, while making these changes it was kept in mind that overall meaning of the text remains same and each version of text has only one changes are compared to the previous version. Following table (changes in each text form is highlighted) shows the all four types of sentiment scores provided by VADER to all these versions of original positive text:  
  
![VADER Positive Sentiment](https://github.com/sachin255701/SentimentAnalysis/blob/main/images/Vader_positive_table.png?raw=true)
So, from the above table it can be observed that initial text has compound score of around 44% categorizing this as a positive text. As expected, by adding a new word “very” increases the compound score. However, when two exclamation marks are added to the end of the text, we can see that compound score increases from 49% to 58% making the text even more positive. Similarly, we can see that by adding happy face emoji and by doing the capitalization of the word that has positive connotation attached to it, the score increases further to 75% and 80% respectively.  
The similar experiment can be performed, but this time with the negative text. The table below shows the similar trends with the negative texts as well. For instance, when a sad face emoji is added or a word “worsen” is capitalized which has negative connotation attached to it, the VADER makes the compound score more negative thus classifying the text as having a higher value of negative sentiment as compared to the original negative text. Following table shows various negative forms of the text and their corresponding sentiment scores derived by VADER:  
  
![VADER Negative Sentiment](https://github.com/sachin255701/SentimentAnalysis/blob/main/images/Vader_negative_table.png?raw=true)

# Automatic Sentiment Analysis
For this section, following machine/deep learning models are used:
1. Naive Bayes
2. Logistic Regression
3. ANN
4. LSTM

The LSTM gave achieves the highest accuracy, precision and recall score. But Logistic regression was the most efficient model as its accuracy, precision and recall were only ~1% less than LSTM but the time consumed by logistic regression was only 17.19 seconds as compared to LSTM’s training time 547.41 seconds. The summarized comparison data can be seen in the following table. 
  
![Model Comparison](https://github.com/sachin255701/SentimentAnalysis/blob/main/images/model_comp.png?raw=true)
Model Comparison considering the time and accuracy tradeoff, we can confidently conclude that Logistic Regression is the most efficient, out of the models which we analyzed, as it achieves high accuracies with very small model training times.

# References
[1] Hutto, C., & Gilbert, E. (2014). VADER: A Parsimonious Rule-Based Model for Sentiment Analysis of Social Media Text. Proceedings of the International AAAI Conference on Web and Social Media.
